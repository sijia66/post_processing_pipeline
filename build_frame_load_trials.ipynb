{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO-DO\n",
    "1. assign the loadlfp output to mtf output \n",
    "1. assign dims to xarray++\n",
    "1. then build a frame\n",
    "1. read MTF doc as to how to apply mtf to post-analysis moving data (seems to be doable, forgot to set default params, eh)\n",
    "2. Pipemodule: make a factory method, and change the params\n",
    "3. nd a status tracker as we go along the th. right  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes to clarify my fuzzy thinking\n",
    "\n",
    "1. should frame take module as class and implement its own logic? \n",
    "    1. so, it can create classes inside itself.\n",
    "    2. bad news is that it would increate computational complexity, eh. \n",
    "    \n",
    "2. pipeframe: should the run_mod class handle the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T14:39:22.537997Z",
     "start_time": "2020-09-29T14:39:14.776339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import succeeded\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import xarray as xr\n",
    "from engines_interfaces import PipeModule, PipeFrame\n",
    "from aopy import datareader\n",
    "import numpy as np\n",
    "\n",
    "print('import succeeded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: can w automate t whole process o returning a fxn? \n",
    "t desgn pat is a factory pattern srt of th.\n",
    "i.e a cls t builds mr cls, fun, wil lok into thz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and test the load trial lfp fxn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  cast loadlfp into a module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T14:39:27.748582Z",
     "start_time": "2020-09-29T14:39:27.734670Z"
    }
   },
   "outputs": [],
   "source": [
    "# f now, just inherit the PipModule\n",
    "dim_types = ('TRIAL', 'ELECTRODE', 'FREQ', \"TIME\")\n",
    "\n",
    "\"\"\"\n",
    "# TO-DO\n",
    "-test the thing\n",
    "-cast this into a frame\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# thz is jst a wraper f\n",
    "\n",
    "\n",
    "class PipeTrialLfpLoader(PipeModule):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    output_dims = ('TRIAL', 'ELECTRODE', 'TIME')\n",
    "\n",
    "    _params_name_ordered = ('monkeyDrive', 'trials',)\n",
    "    _params_name_KW = ('task_field', 'bn',\n",
    "                        'microdrive_name', 'file_type',\n",
    "                        'verbose')\n",
    "        \n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        self.output_dims = ('TRIAL', 'ELECTRODE', 'TIME')\n",
    "\n",
    "        self._params_name_ordered = ('monkeyDrive', 'trials',)\n",
    "        self._params_name_KW = ('task_field', 'bn',\n",
    "                                'microdrive_name', 'file_type',\n",
    "                                'verbose')\n",
    "        \n",
    "        \"\"\"\n",
    "        self._params_val_ordered_dict =  dict()\n",
    "        self._params_val_KW_dict = dict()\n",
    "\n",
    "\n",
    "    def run_mod(self):\n",
    "        # adding more logic\n",
    "        # according to the flag, we don't h to run twice, right.\n",
    "        if not self._data_available:\n",
    "            _data = datareader.read_trials_lfp(self._params_val_ordered_dict['monkeyDrive'],\n",
    "                                               self._params_val_ordered_dict['trials'],\n",
    "                                               **self._params_val_KW_dict)\n",
    "\n",
    "            # build xarray 1) cast data into xrray. 2) assign output dims into the dims\n",
    "            self._output_xarray = xr.DataArray(_data,\n",
    "                                         dims=self.output_dims)\n",
    "\n",
    "            # assemble xarray data.\n",
    "            self._data_available = True\n",
    "\n",
    "        # TO-DO if it is okay py c chk self._params_val_dict is treated lk **kwarg\n",
    "        # self._da_xarray = xr.DataArray(_data, dims = self.output_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  test the load frame fxn, eh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:09:23.299220Z",
     "start_time": "2020-09-28T19:09:22.655534Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get a frame srt of th.   \n",
    "\n",
    "trialLfp_loader = PipeTrialLfpLoader()\n",
    "\n",
    "print(trialLfp_loader._params_name_ordered)\n",
    "print(trialLfp_loader._params_name_KW )\n",
    "\n",
    "\n",
    "monkeyDrive = r'E:\\OneDrive - UW\\projects\\Brain EEG\\data'\n",
    "import json\n",
    "rec_date = '180328'\n",
    "mat_folder = 'mat'\n",
    "file_name = 'Trials'\n",
    "JSON_EXT = '.json'\n",
    "trial_file_loc = monkeyDrive + '\\\\'\\\n",
    "                + rec_date +'\\\\'\\\n",
    "                + mat_folder + '\\\\'\\\n",
    "                + file_name + JSON_EXT\n",
    "\n",
    "with open(trial_file_loc,'r') as f:\n",
    "    trials = json.load(f)\n",
    "#\n",
    "trialLfp_args = {\n",
    "    'monkeyDrive': monkeyDrive,\n",
    "    'trials':trials,\n",
    "    'task_field': 'ReachStart',\n",
    "    'bn': np.array([-300, 500]),\n",
    "    'microdrive_name': 'LM1_ECOG_3', \n",
    "    'file_type':'lfp',\n",
    "    'verbose':False\n",
    "}\n",
    "\n",
    "\n",
    "print(trialLfp_args.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now mimick the actual fxn flow\n",
    "1. check if ordered args exist in the args\n",
    "2. assign the params to the internal parameter list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:09:29.880551Z",
     "start_time": "2020-09-28T19:09:29.869591Z"
    }
   },
   "outputs": [],
   "source": [
    "#check compatibility of course\n",
    "# this is a sort of flow\n",
    "trialLfp_loader.check_ordered_args_exist(trialLfp_args)\n",
    "# now we can run the srt of thing, eh?\n",
    "\n",
    "# assign params value\n",
    "trialLfp_loader.assign_params_value(trialLfp_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## call run module to run the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:09:36.179759Z",
     "start_time": "2020-09-28T19:09:35.013114Z"
    }
   },
   "outputs": [],
   "source": [
    "# TO-DO\n",
    "# write a test to check how the program behave:\n",
    "# arguments are not checked\n",
    "# write a flow diagram srt o thing, eh.\n",
    "\n",
    "trialLfp_loader.run_mod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:09:41.169611Z",
     "start_time": "2020-09-28T19:09:41.140687Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the xarray\n",
    "output_array = trialLfp_loader.get_data_xarray()\n",
    "output_array.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this actually really well,\n",
    "sd we explain to Amy what is happening, here?  blame interdependancies of our root cause,eh. \n",
    "this is very clear, we wil see if it act works or not,eh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore xarray params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:09:47.966977Z",
     "start_time": "2020-09-28T19:09:47.926137Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'output_array.value type {type(output_array.data)}')\n",
    "\n",
    "print(f'output_array.shape type {(output_array.shape)}')\n",
    "\n",
    "sel_range = dict(TIME=slice(200))\n",
    "output_array[sel_range]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# adapt MTF from nitime\n",
    "use multitaper meth as an eg.\n",
    "nitime: time series anal in python\n",
    "1. used in BMI3D, in fact, this is wher I fd abot it. \n",
    "can find the exact def in:\n",
    "https://github.com/nipy/nitime/blob/6f95beabf337a16ed882067f2ea3d0b32399c901/nitime/algorithms/spectral.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test out MTF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T14:11:59.808969Z",
     "start_time": "2020-09-29T14:11:59.804021Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# for the input array.\n",
    "# time is assumed to be on the last axis.\n",
    "# which is clearly the case,\n",
    "# it just converts to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:16:21.111798Z",
     "start_time": "2020-09-28T19:16:20.868789Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "trial_xarray = output_array.isel(TRIAL=0, ELECTRODE=slice(2))\n",
    "\n",
    "freqs, psd_est, var_or_nu = tsa.multi_taper_psd(trial_xarray.data,\n",
    "                                                Fs=1000)  # magic!\n",
    "# we h an array, because, we pass on an xarray and it does not have reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:16:26.408911Z",
     "start_time": "2020-09-28T19:16:26.397945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(trial_xarray.data.shape)\n",
    "print(trial_xarray.dims)\n",
    "\n",
    "print(psd_est.shape)\n",
    "print(freqs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cast MTF into a  pipemodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T14:39:36.592941Z",
     "start_time": "2020-09-29T14:39:36.462225Z"
    }
   },
   "outputs": [],
   "source": [
    "# I screwed big time in this,eht\n",
    "\n",
    "# thz is jst a wraper f\n",
    "import nitime.algorithms as tsa\n",
    "\n",
    "class PipeMultiTaperEstimater(PipeModule):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    input_dims = ('TRIAL', 'ELECTRODE','TIME')\n",
    "    output_dims = ('TRIAL', 'ELECTRODE','FREQ')\n",
    "    \n",
    "    _params_name_ordered = ('DATA',)\n",
    "    _params_name_kwd = ('Fs', 'Nw')\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mod_name = self.__class__.__name__\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "                # ASSUME: this is the output dims for tsa.\n",
    "        self.output_dims = ('TRIAL', 'ELECTRODE','FREQ')\n",
    "\n",
    "        self._params_name_ordered = ('DATA',)\n",
    "        self._params_name_kwd = ('Fs', 'Nw')\n",
    "        \n",
    "        \"\"\"\n",
    "        self._params_val_ordered_dict =  dict()\n",
    "        self._params_val_KW_dict = dict()\n",
    "        \n",
    "        self._data_available = False \n",
    "    \n",
    "\n",
    "    def run_mod(self):\n",
    "        # for mor detail go to nitime.algorithms.spectral\n",
    "        if not self._data_available:\n",
    "            freqs, psd_est, var_or_nu = tsa.multi_taper_psd(self._params_val_dict['DATA'].values,\n",
    "                                                            **self._params_val_KW_dict)\n",
    "            # build xarray 1) cast data into xrray. 2) assign output dims into the dims\n",
    "            self._output_xarray = xr.DataArray(psd_est,\n",
    "                                         dims=self.output_dims)\n",
    "            self._data_available = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test the mtf module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:18:46.027827Z",
     "start_time": "2020-09-28T19:18:46.017855Z"
    }
   },
   "outputs": [],
   "source": [
    "mtf = PipeMultiTaperEstimater()\n",
    "\n",
    "print(mtf._params_name_ordered)\n",
    "\n",
    "\n",
    "trial_xarray = output_array.isel(TRIAL= slice(2), ELECTRODE=slice(2))\n",
    "\n",
    "print(trial_xarray.shape)\n",
    "\n",
    "#this is where the magic happens, right? \n",
    "mtf_args = {\n",
    "    'DATA':trial_xarray,\n",
    "    'Fs': 1000,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:18:51.949199Z",
     "start_time": "2020-09-28T19:18:51.941220Z"
    }
   },
   "outputs": [],
   "source": [
    "#check compatibility of course\n",
    "# this is a sort of flow\n",
    "print(mtf.check_ordered_args_exist(mtf_args))\n",
    "# now we can run the srt of thing, eh?\n",
    "\n",
    "# assign params value\n",
    "mtf.assign_params_value(mtf_args)\n",
    "\n",
    "print(mtf._params_val_KW_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## can actually run the params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T19:18:57.779002Z",
     "start_time": "2020-09-28T19:18:57.628866Z"
    }
   },
   "outputs": [],
   "source": [
    "mtf.run_mod()\n",
    "mtf_output = mtf.get_data_xarray()\n",
    "print(type(mtf_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# link trialLfp to MTF using frames\n",
    "\n",
    "assume they are welrtn A tsted, whch thy n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build a loadlfp frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T14:39:56.014426Z",
     "start_time": "2020-09-29T14:39:56.007497Z"
    }
   },
   "outputs": [],
   "source": [
    "trialLFPload_frame = PipeFrame(frame_type = 'input', module = PipeTrialLfpLoader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test out the loadlfp frame, eh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T14:40:30.378033Z",
     "start_time": "2020-09-29T14:40:28.353125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['monkeyDrive', 'trials', 'task_field', 'bn', 'microdrive_name', 'file_type', 'verbose'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<bound method PipeModule.get_data_xarray of <__main__.PipeTrialLfpLoader object at 0x0000022E5D5EC1C8>>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monkeyDrive = r'E:\\OneDrive - UW\\projects\\Brain EEG\\data'\n",
    "import json\n",
    "rec_date = '180328'\n",
    "mat_folder = 'mat'\n",
    "file_name = 'Trials'\n",
    "JSON_EXT = '.json'\n",
    "trial_file_loc = monkeyDrive + '\\\\'\\\n",
    "                + rec_date +'\\\\'\\\n",
    "                + mat_folder + '\\\\'\\\n",
    "                + file_name + JSON_EXT\n",
    "\n",
    "with open(trial_file_loc,'r') as f:\n",
    "    trials = json.load(f)\n",
    "#\n",
    "trialLfp_args = {\n",
    "    'monkeyDrive': monkeyDrive,\n",
    "    'trials':trials,\n",
    "    'task_field': 'ReachStart',\n",
    "    'bn': np.array([-300, 500]),\n",
    "    'microdrive_name': 'LM1_ECOG_3', \n",
    "    'file_type':'lfp',\n",
    "    'verbose':False\n",
    "}\n",
    "\n",
    "\n",
    "print(trialLfp_args.keys())\n",
    "\n",
    "# go through the process, eh\n",
    "trialLFPload_frame._create_instances()\n",
    "trialLFPload_frame._assign_params_to_mod(trialLfp_args)\n",
    "trialLFPload_frame.run_frame()\n",
    "\n",
    "frame_output_dict = trialLFPload_frame.get_frame_data()\n",
    "#we can get data, we do not have to, at this time. \n",
    "frame_output_list = trialLFPload_frame.get_frame_data()\n",
    "frame_output_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up a mtf frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T14:24:20.784204Z",
     "start_time": "2020-09-29T14:24:20.720354Z"
    }
   },
   "outputs": [],
   "source": [
    "# ASSUM PipeTrialLfpLoader A PipeMultiTaperEstimater h b blt to t spec\n",
    "# ASSUM: PipeFrame h b blt, unver of crse\n",
    "\n",
    "# now, bld two frames\n",
    "# build t estimater frame 1st\n",
    "\n",
    "\n",
    "mtf_estimaters_frame = PipeFrame(frame_type = 'proc', module = PipeMultiTaperEstimater)\n",
    "\n",
    "# INS,\n",
    "# d t same th. for ld\n",
    "# aft tht, run check compat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  test out the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-29T14:26:49.986638Z",
     "start_time": "2020-09-29T14:26:49.553637Z"
    }
   },
   "outputs": [],
   "source": [
    "mtf_parameters = {\n",
    "    'Fs': 1000,\n",
    "    'NW': np.arange(1, 10),  # normalized  half-bandwidth\n",
    "    'BW': np.arange(10, 20)  # sampl rela bandwidth\n",
    "}\n",
    "\n",
    "mtf_estimaters_frame._create_instances()\n",
    "mtf_estimaters_frame._assign_params_to_mod(mtf_parameters)\n",
    "mtf_estimaters_frame.run_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T19:58:02.373179Z",
     "start_time": "2020-09-26T19:58:02.368232Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# set up a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# some debugging tries\n",
    "they don't add to the story at this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T18:54:46.340268Z",
     "start_time": "2020-09-28T18:54:38.365Z"
    }
   },
   "outputs": [],
   "source": [
    "#some one provided a function to do this. \n",
    "\n",
    "def reorder_dims(darray, dim1, dim2):\n",
    "    \"\"\"\n",
    "    Interchange two dimensions of a DataArray in a similar way as numpy's swap_axes\n",
    "    \"\"\"\n",
    "    dims = list(darray.dims)\n",
    "    assert set([dim1,dim2]).issubset(dims), 'dim1 and dim2 must be existing dimensions in darray'\n",
    "    ind1, ind2 = dims.index(dim1), dims.index(dim2)\n",
    "    dims[ind2], dims[ind1] = dims[ind1], dims[ind2]\n",
    "    return darray.transpose(*dims)\n",
    "\n",
    "\n",
    "#now we can do transpose\n",
    "new_dims_in_tuple = ('TIME', 'ELECTRODE', 'TRIAL')\n",
    "print(new_dims_in_tuple)\n",
    "\n",
    "print(f'shape before transpose:{output_array.dims}')\n",
    "\n",
    "output_array = output_array.transpose(*new_dims_in_tuple)\n",
    "\n",
    "print(f'shape after transpose:{output_array.dims}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T18:54:46.355891Z",
     "start_time": "2020-09-28T18:54:38.374Z"
    }
   },
   "outputs": [],
   "source": [
    "dims_as_list = list(output_array.dims)\n",
    "\n",
    "print('list of dim names before remove time:')\n",
    "print(dims_as_list)\n",
    "\n",
    "dims_as_list.remove('TIME')\n",
    "print('list after remove time:')\n",
    "print(dims_as_list)\n",
    "\n",
    "dims_as_list.append('TIME')\n",
    "print('list after time to the last pos:')\n",
    "print(dims_as_list)\n",
    "\n",
    "new_dims_in_tuple =  tuple(dims_as_list)\n",
    "\n",
    "new_dims_in_tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check if an object is a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T18:54:46.355891Z",
     "start_time": "2020-09-28T18:54:38.379Z"
    }
   },
   "outputs": [],
   "source": [
    "class x:\n",
    "    pass\n",
    "\n",
    "class y(x):\n",
    "    pass\n",
    "#y = 1\n",
    "\n",
    "temp_list = [x, y]\n",
    "\n",
    "type_check_list = [isinstance(i, type) for i in temp_list]\n",
    "type_check_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-28T18:54:46.355891Z",
     "start_time": "2020-09-28T18:54:38.384Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if insubclass works\n",
    "print(f'check all lists are classes or types: {type_check_list}')\n",
    "\n",
    "x_ins = x()\n",
    "issubclass(x, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "273.333px",
    "left": "83px",
    "top": "110.972px",
    "width": "276.107px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "424.499px",
    "left": "953.749px",
    "right": "20px",
    "top": "131.999px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
